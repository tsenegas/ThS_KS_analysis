[
  {
    "objectID": "R_Analysis.html",
    "href": "R_Analysis.html",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "",
    "text": "Show the code\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(skimr)\nlibrary(lubridate)\nlibrary(highcharter)\nlibrary(tidytext)\nlibrary(textdata)\nlibrary(tidymodels)\nlibrary(vip)"
  },
  {
    "objectID": "R_Analysis.html#load-and-clean-raw-dataset",
    "href": "R_Analysis.html#load-and-clean-raw-dataset",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "Load and clean raw dataset",
    "text": "Load and clean raw dataset\n\n\nShow the code\ndf_raw = read.csv(\"data/ks_dataset.csv\")\n\n\nIl apparaît que certaines observations dans le jeu de données sont décalées, générant ainsi quatre colonnes presque vides (X à X.3). Nous pourrions prendre le temps de corriger ces observations, mais étant donné qu’elles sont peu nombreuses, j’ai choisi de ne conserver que les observations correctes.\n\n\nShow the code\nexistring_category = as.data.frame(table(df_raw$category)) |&gt;\n    subset(Freq &gt;= 10 )\n\ndf = df_raw |&gt;\n    subset(category %in% existring_category$Var1) |&gt;\n    select(-X, -X.1, -X.2, -X.3)\n\n\nNous disposons désormais d’un jeu de données propre, avec une perte limitée à seulement 632 observations."
  },
  {
    "objectID": "R_Analysis.html#cleaning",
    "href": "R_Analysis.html#cleaning",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "Cleaning",
    "text": "Cleaning\n\n\nShow the code\ndf = df |&gt;\n    mutate(\n        category = factor(category),\n        main_category = factor(main_category),\n        currency = factor(currency),\n        state = factor(state),\n        country = factor(country),\n        deadline = lubridate::ymd_hms(deadline),\n        launched = lubridate::ymd_hms(launched),\n        goal = as.numeric(goal),\n        pledged = as.numeric(pledged),\n        backers = as.numeric(backers),\n        usd.pledged = as.numeric(usd.pledged)\n        )\n\nskimr::skim(df)\n\n\n\nData summary\n\n\nName\ndf\n\n\nNumber of rows\n323118\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n5\n\n\nnumeric\n5\n\n\nPOSIXct\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n1\n1\n1\n96\n0\n321005\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ncategory\n0\n1\nFALSE\n158\nPro: 17477, Doc: 14891, Mus: 13907, Sho: 11681\n\n\nmain_category\n0\n1\nFALSE\n15\nFil: 57662, Mus: 46718, Pub: 34221, Gam: 28005\n\n\ncurrency\n0\n1\nFALSE\n13\nUSD: 260298, GBP: 27968, CAD: 12197, EUR: 11555\n\n\nstate\n0\n1\nFALSE\n6\nfai: 168221, suc: 113081, can: 32354, liv: 4428\n\n\ncountry\n0\n1\nFALSE\n22\nUS: 257565, GB: 27509, CA: 11992, AU: 6236\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nID\n0\n1.00\n1.074901e+09\n619312343.84\n5971.00\n537572149\n1075764205\n1611025056\n2147476221\n▇▇▇▇▇\n\n\ngoal\n0\n1.00\n4.715252e+04\n1139577.48\n0.01\n2000\n5000\n15000\n100000000\n▇▁▁▁▁\n\n\npledged\n0\n1.00\n8.696730e+03\n89586.41\n0.00\n30\n610\n3938\n20338986\n▇▁▁▁▁\n\n\nbackers\n0\n1.00\n1.016300e+02\n934.92\n0.00\n2\n12\n55\n219382\n▇▁▁▁▁\n\n\nusd.pledged\n3790\n0.99\n7.847680e+03\n84684.05\n0.00\n25\n535\n3575\n20338986\n▇▁▁▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndeadline\n0\n1\n2009-05-03 08:59:59\n2017-02-04 08:54:55\n2014-09-07 17:59:12\n294796\n\n\nlaunched\n0\n1\n1970-01-01 01:00:00\n2016-12-06 10:18:31\n2014-08-05 01:15:39\n322631\n\n\n\n\n\nExaminons la distribution des projets lancés au fil des années :\n\n\nShow the code\ntable(lubridate::year(df$launched)) \n\n\n\n 1970  2009  2010  2011  2012  2013  2014  2015  2016 \n    7  1324 10491 26174 41090 44755 67602 77180 54495 \n\n\nNous constatons que 7 projets ont été lancés en 1970 et seulement 1 324 en 2009. Nous allons supprimer ces projets afin de travailler avec des années complètes.\n\n\nShow the code\ndf = df |&gt;\n    dplyr::filter(!(lubridate::year(launched) %in% c(1970, 2009)))\n\n\nFaisons une dernière vérification pour nous assurer qu’il n’y a pas de valeurs manquantes.\n\n\nShow the code\nsapply(df, function(x) sum(is.na(x)))\n\n\n           ID          name      category main_category      currency \n            0             1             0             0             0 \n     deadline          goal      launched       pledged         state \n            0             0             0             0             0 \n      backers       country   usd.pledged \n            0             0          3790 \n\n\nNous avons une observation avec un ‘name’ manquant et 3 790 observations avec un ‘usd.pledged’ manquant. Par souci de simplicité, nous allons retirer ces observations. Il aurait également été possible de retrouver le taux de change du jour et de réintégrer la valeur correcte pour ‘usd.pledged’.\n\n\nShow the code\ndf = df[complete.cases(df), ]\n\n\nPour simplifier l’analyse, nous allons recoder notre variable cible ‘state’ en une variable binaire. Par la même occasion, nous supprimerons les projets ayant un état ‘undefined’ ou ‘live’.\n\n\nShow the code\ndf = df |&gt;\n    dplyr::filter(state %in% c(\"failed\", \"canceled\", \"successful\", \"suspended\")) |&gt;\n    mutate(\n        state_binary = factor(ifelse(state == \"successful\", 1, 0))\n    )\n\ntable(df$state_binary)\n\n\n\n     0      1 \n201169 112400 \n\n\nSur les 313,569 projets dans notre jeu de données, 112,400 ont été financés, ce qui représente environ 36 %. Bien que notre jeu de données ne soit pas parfaitement équilibré, nous allons le garder tel quel."
  },
  {
    "objectID": "R_Analysis.html#data-visualizations",
    "href": "R_Analysis.html#data-visualizations",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "Data Visualizations",
    "text": "Data Visualizations\n\n\nShow the code\nplot_success_per_year &lt;- df |&gt;\n    mutate(\n        year_launch = lubridate::year(launched),\n        state_binary = factor(state_binary, levels = c(0, 1), labels = c(\"Failed\", \"Success\"))\n    ) |&gt;\n     group_by(year_launch, state_binary) |&gt;\n     summarise(n_proj = n()) |&gt;\n    highcharter::hchart('column', hcaes(x = year_launch, y = n_proj, group = state_binary),\n    stacking = 'normal'\n    ) |&gt;\n        hc_colors(c(\"rgb(155, 20, 20)\", \"rgba(8, 160, 31, 0.5)\")) |&gt;\n        hc_title(text = \"Nombre de projets 'successful' et 'failed' par années\") |&gt;\n        hc_xAxis(title = list(text = \"Année de lancement\")) |&gt;\n        hc_yAxis(title = list(text = \"Nombre de projets\")) \n \n \nplot_success_per_year\n\n\n\n\n\n\n\n\nShow the code\nplot_success_percent_per_year &lt;- df |&gt;\n    mutate(\n        year_launch = lubridate::year(launched),\n        state_binary = factor(state_binary, levels = c(0, 1))\n    ) |&gt;\n     group_by(year_launch) |&gt;\n     summarise(succ_rate = round((mean(as.numeric(state_binary) - 1)) * 100)) |&gt;\n    highcharter::hchart('column', hcaes(x = year_launch, y = succ_rate),\n    stacking = 'normal'\n    ) |&gt;\n        hc_title(text = \"Taux de réussite par années\") |&gt;\n        hc_xAxis(title = list(text = \"Année de lancement\")) |&gt;\n        hc_yAxis(title = list(text = \"Taux réussite (%)\")) \n \n \nplot_success_percent_per_year\n\n\n\n\n\n\n\n\nShow the code\nplot_usd_invest_per_year &lt;- df |&gt;\n    mutate(\n        year_launch = lubridate::year(launched),\n        state_binary = factor(state_binary, levels = c(0, 1), labels = c(\"Failed\", \"Success\"))\n    ) |&gt;\n     group_by(year_launch, state_binary) |&gt;\n     summarise(pledged_per_year = round(sum(usd.pledged) / 1000000)) |&gt; \n    highcharter::hchart('column', hcaes(x = year_launch, y = pledged_per_year, group = state_binary),\n    stacking = 'normal'\n    ) |&gt;\n        hc_colors(c(\"rgb(155, 20, 20)\", \"rgba(8, 160, 31, 0.5)\")) |&gt;\n        hc_title(text = \"Total d'argent investis par années\") |&gt;\n        hc_xAxis(title = list(text = \"Année de lancement\")) |&gt;\n        hc_yAxis(title = list(text = \"USD en million\")) \n \nplot_usd_invest_per_year\n\n\n\n\n\n\n\n\nShow the code\nplot_avg_goal_year_usd &lt;- df |&gt;\n    subset(currency == 'USD') |&gt;\n    mutate(\n        year_launch = lubridate::year(launched),\n        state_binary = factor(state_binary, levels = c(0, 1), labels = c(\"Failed\", \"Success\"))\n    ) |&gt;\n     group_by(year_launch, state_binary) |&gt;\n     summarise(goal_per_year = round(mean(goal))) |&gt; \n    highcharter::hchart('column', hcaes(x = year_launch, y = goal_per_year, group = state_binary),\n    stacking = 'normal'\n    ) |&gt;\n        hc_colors(c(\"rgb(155, 20, 20)\", \"rgba(8, 160, 31, 0.5)\")) |&gt;\n        hc_title(text = \"Moyenne des Goal des projets (Projets en USD)\") |&gt;\n        hc_xAxis(title = list(text = \"Année de lancement\")) |&gt;\n        hc_yAxis(title = list(text = \"USD\")) \n \nplot_usd_invest_per_year\n\n\n\n\n\n\nAvec ces 4 visualisations simples nous pouvons voir les choses suivantes : - Le nombre de projets déposés sur kickstarter a augmenté pour atteindre son piqu en 2015 - Cette augmentation ne se traduit pas par un taux de succés stable, au contraire. - Si l’on regarde la somme d’argent investis par années (en millions de USD), en séparant les projets financés et ceux qui échouent, nous pouvons penser que c’est quitte ou double pour un projet. Soit celui-ci est financé totalement soit il recoit très peu d’investissement et il échoue. - En nous basant uniquement sur les projets en USD, la moyenne pour les projets qui réussisse de l’objectif (en USD) sont nettement inférieur à la moyenne des objectifs (en USD) des projets qui échouent.\nExplorons maintenant les category / main_category des projets, leur taux de réussite, ainsi que la durée des projets déposés et le pays dans lequel sont déposés les projets.\nAvec ces quatre visualisations simples, nous pouvons observer les points suivants :\n\nLe nombre de projets déposés sur Kickstarter a augmenté, atteignant un pic en 2015.\nCette augmentation n’a pas entraîné un taux de succès stable ; au contraire, le taux de succès semble diminuer.\nEn examinant les sommes investies par année (en millions de USD), en distinguant les projets financés de ceux qui échouent, on constate que les projets semblent avoir une issue binaire : soit ils sont complètement financés, soit ils reçoivent très peu d’investissements et échouent.\nEn nous basant uniquement sur les projets en USD, la moyenne des objectifs de financement (en USD) pour les projets ayant réussi est nettement inférieure à la moyenne des objectifs de financement (en USD) des projets ayant échoué.\n\nExplorons maintenant les catégories et sous-catégories des projets, leur taux de réussite, ainsi que la durée des projets et les pays d’origine.\n\n\nShow the code\ndf &lt;- df |&gt;\n    mutate(\n        duration = round(deadline - launched)\n    )\n\n\n\n\nShow the code\nplot_main_category_success &lt;- df |&gt;\n    mutate(\n        year_launch = lubridate::year(launched),\n        state_binary = factor(state_binary, levels = c(0, 1), labels = c(\"Failed\", \"Success\"))\n    ) |&gt;\n        group_by(main_category, state_binary) |&gt;\n        summarise(n_proj = n()) |&gt;\n        arrange(desc(n_proj))|&gt; \n        highcharter::hchart('column', hcaes(x = main_category, y = n_proj, group = state_binary),\n    stacking = 'normal'\n    ) |&gt;\n        hc_colors(c(\"rgb(155, 20, 20)\", \"rgba(8, 160, 31, 0.5)\")) |&gt;\n        hc_title(text = \"Nombre de projets Failed & Succed par main_catergory\") |&gt;\n        hc_xAxis(title = list(text = \"Main Category\")) |&gt;\n        hc_yAxis(title = list(text = \"nombre projet\")) \n \nplot_main_category_success\n\n\n\n\n\n\n\n\nShow the code\nplot_duration_success &lt;- df |&gt;\n    mutate(\n        year_launch = lubridate::year(launched),\n        state_binary = factor(state_binary, levels = c(0, 1), labels = c(\"Failed\", \"Success\"))\n    ) |&gt;\n        group_by(duration, state_binary) |&gt;\n        summarise(n_proj = n()) |&gt;\n        arrange(desc(n_proj))|&gt; \n        highcharter::hchart('column', hcaes(x = duration, y = n_proj, group = state_binary),\n    stacking = 'normal'\n    ) |&gt;\n        hc_colors(c(\"rgb(155, 20, 20)\", \"rgba(8, 160, 31, 0.5)\")) |&gt;\n        hc_title(text = \"Nombre de projets Failed & Succed par durée\") |&gt;\n        hc_xAxis(title = list(text = \"Durée (jours)\")) |&gt;\n        hc_yAxis(title = list(text = \"nombre projet\")) \n \nplot_duration_success\n\n\n\n\n\n\n\n\nShow the code\nplot_country_success &lt;- df |&gt;\n    mutate(\n        year_launch = lubridate::year(launched),\n        state_binary = factor(state_binary, levels = c(0, 1), labels = c(\"Failed\", \"Success\"))\n    ) |&gt;\n        group_by(country, state_binary) |&gt;\n        summarise(n_proj = n()) |&gt;\n        arrange(desc(n_proj))|&gt; \n        highcharter::hchart('column', hcaes(x = country, y = n_proj, group = state_binary),\n    stacking = 'normal'\n    ) |&gt;\n        hc_colors(c(\"rgb(155, 20, 20)\", \"rgba(8, 160, 31, 0.5)\")) |&gt;\n        hc_title(text = \"Nombre de projets Failed & Succed par pays\") |&gt;\n        hc_xAxis(title = list(text = \"Pays\")) |&gt;\n        hc_yAxis(title = list(text = \"nombre projet\")) \n \nplot_country_success\n\n\n\n\n\n\n\n\nShow the code\nplot_country_success_perc &lt;- df |&gt;\n    mutate(\n        year_launch = lubridate::year(launched),\n        state_binary = factor(state_binary, levels = c(0, 1), labels = c(\"Failed\", \"Success\"))\n    ) |&gt;\n        group_by(country, state_binary) |&gt;\n        summarise(n_proj = n()) |&gt;\n        arrange(desc(n_proj))|&gt; \n        ungroup() |&gt;\n        group_by(country) |&gt;\n        mutate(\n            total_proj = sum(n_proj),\n            perc = n_proj / total_proj * 100\n        ) |&gt;\n            highcharter::hchart('column', hcaes(x = country, y = perc, group = state_binary),\n    stacking = 'normal'\n    ) |&gt;\n        hc_colors(c(\"rgb(155, 20, 20)\", \"rgba(8, 160, 31, 0.5)\")) |&gt;\n        hc_title(text = \"Nombre de projets Failed & Succed par Pays (en %)\") |&gt;\n        hc_xAxis(title = list(text = \"Pays\")) |&gt;\n        hc_yAxis(title = list(text = \"\")) \n \nplot_country_success_perc\n\n\n\n\n\n\nEn examinant ces visualisations supplémentaires, nous constatons que la grande majorité des projets ont une durée de 30 jours et sont lancés aux États-Unis. L’objectif de financement (goal) en USD semble avoir un impact significatif sur le critère de réussite ou d’échec du financement du projet."
  },
  {
    "objectID": "R_Analysis.html#features-selections-pour-le-modèle",
    "href": "R_Analysis.html#features-selections-pour-le-modèle",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "Features selections pour le modèle",
    "text": "Features selections pour le modèle\n\nmain_category\ngoal\nduration\nNous allons filtrer nos données pour faire un modèle uniquement pour les projets aux États-Unis\n\nEnfin, il semble important de prendre en compte le nom du projet. Nous allons calculer un score d’analyse de sentiment à partir des noms des projets et l’inclure dans notre modèle."
  },
  {
    "objectID": "R_Analysis.html#afinn-lexicon",
    "href": "R_Analysis.html#afinn-lexicon",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "AFINN Lexicon",
    "text": "AFINN Lexicon\nNous aurions pu utiliser différents lexiques et comparer les résultats. Pour l’instant, je vais continuer avec le lexique AFINN.\n\n\nShow the code\ndf_afinn = df |&gt;\n    tidytext::unnest_tokens(word, name) |&gt;\n    inner_join(tidytext::get_sentiments(\"afinn\"), by = \"word\") |&gt;\n    group_by(ID) |&gt;\n    mutate(\n        overall_sent = sum(value)\n    ) |&gt;\n    select(ID, overall_sent) |&gt;\n    unique()\n\ndf_afinn_clean &lt;- left_join(df, df_afinn, by = \"ID\")\n\ndf_afinn_clean$overall_sent |&gt; is.na() |&gt; sum()\n\n\n[1] 182618\n\n\nNous constatons que de nombreux projets ont un score de sentiment manquant (NA). Nous ferons l’hypothèse que ces projets ont un sentiment neutre et nous imputerons une valeur de 0 pour le sentiment à ces projets.\n\n\nShow the code\ndf_afinn_clean &lt;- df_afinn_clean %&gt;% \n  replace_na(list(overall_sent = 0))\n\n\nRegarons avec un modèle très simple si le score de sentiment du nom d’un projet peut avoir un effet sur la réussite de celui-ci :\n\n\nShow the code\nsummary(glm(state_binary ~ overall_sent, data = df_afinn_clean, family = \"binomial\"))\n\n\n\nCall:\nglm(formula = state_binary ~ overall_sent, family = \"binomial\", \n    data = df_afinn_clean)\n\nCoefficients:\n              Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept)  -0.503950   0.004183 -120.481  &lt; 2e-16 ***\noverall_sent -0.018711   0.003228   -5.796 6.79e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 335571  on 253525  degrees of freedom\nResidual deviance: 335537  on 253524  degrees of freedom\nAIC: 335541\n\nNumber of Fisher Scoring iterations: 4\n\n\nLe score de sentiment a un effet significatif, bien que son poids soit relativement faible. Nous conserverons tout de même cette variable dans notre modèle, notamment pour d’éventuelles analyses plus approfondies par catégorie ou sous-catégorie."
  },
  {
    "objectID": "R_Analysis.html#data-prep",
    "href": "R_Analysis.html#data-prep",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "Data prep",
    "text": "Data prep\nVoici les variables que nous allons selectionnés pour notre modèle : - main_category - goal - duration - overall_sent\n\n\nShow the code\ndf_model = df_afinn_clean |&gt;\n    select(state_binary, overall_sent, main_category, goal, duration) |&gt;\n    mutate(\n        duration = as.numeric(duration)\n    )"
  },
  {
    "objectID": "R_Analysis.html#data-modelling-prep",
    "href": "R_Analysis.html#data-modelling-prep",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "Data Modelling & Prep",
    "text": "Data Modelling & Prep\nNous allons commencer par tester un modèle de régression logistique pénalisée. Ce modèle présente plusieurs avantages, notamment :\n\nIntégration des techniques Lasso (régularisation L1) et Ridge (régularisation L2)\nPrévention de l’overfitting\nSélection des variables (avec Lasso)\nRéduction de la multicolinéarité (avec Ridge)\n\n\nData Splitting & resampling\nIci, plutôt que d’utiliser plusieurs itérations de rééchantillonnage, nous avons créé un seul rééchantillon, appelé val_set. Le graphique ci-dessous illustre notre partitionnement des données et notre rééchantillonnage.\n\n\n\nShow the code\nset.seed(123)\n\nsplits &lt;- initial_split(df_model, strata = state_binary)\n\ndf_other &lt;- training(splits)\ndf_test &lt;- testing(splits)\n\nval_set &lt;- validation_split(df_other, \n                            strata = state_binary, \n                            prop = 0.80)"
  },
  {
    "objectID": "R_Analysis.html#penalized-logistic-regression",
    "href": "R_Analysis.html#penalized-logistic-regression",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "penalized logistic regression",
    "text": "penalized logistic regression\n\n\nShow the code\nlr_mod &lt;- logistic_reg(penalty = tune(), mixture = 1) |&gt;\n    set_engine(\"glmnet\")\n\n\nIci, nous réglons le paramètre de mixture à 1 pour obtenir le modèle le plus simple possible, en privilégiant ainsi la régularisation Lasso.\n\n\nShow the code\nlr_recipe &lt;- \n  recipe(state_binary ~ ., data = df_other) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_zv(all_predictors()) %&gt;% \n  step_normalize(all_predictors())\n\nlr_workflow &lt;- \n  workflow() %&gt;% \n  add_model(lr_mod) %&gt;% \n  add_recipe(lr_recipe)\n\n\n\nstep_dummy(): Convertit les variables catégorielles (caractères ou facteurs) en un ou plusieurs termes binaires numériques représentant chaque niveau des données d’origine.\nstep_zv(): Supprime les variables indicatrices qui contiennent uniquement une valeur unique (par exemple, des zéros). Cela est important pour les modèles pénalisés, car les prédicteurs doivent être centrés et mis à l’échelle.\nstep_normalize(): Centre et met à l’échelle les variables numériques.\n\n\n\nShow the code\nlr_reg_grid &lt;- tibble(penalty = 10^seq(-4, -1, length.out = 30))\n\n\n\n\nShow the code\nlr_res &lt;- \n  lr_workflow %&gt;% \n  tune_grid(val_set,\n            grid = lr_reg_grid,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(roc_auc))\n\n\n\n\nShow the code\nlr_plot &lt;- \n  lr_res %&gt;% \n  collect_metrics() %&gt;% \n  ggplot(aes(x = penalty, y = mean)) + \n  geom_point() + \n  geom_line() + \n  ylab(\"Area under the ROC Curve\") +\n  scale_x_log10(labels = scales::label_number())\n\nlr_plot \n\n\n\n\n\n\n\n\n\nCe graphique montre que les performances du modèle sont généralement meilleures lorsque les valeurs de pénalité sont plus faibles. Cela suggère que la plupart des prédicteurs sont importants pour le modèle. Étant donné que nous avons sélectionné un nombre limité de variables pour ce modèle, cela semble cohérent.\n\n\nShow the code\nselect_best(lr_res, metric = 'roc_auc')\n\n\n# A tibble: 1 × 2\n  penalty .config              \n    &lt;dbl&gt; &lt;chr&gt;                \n1  0.0001 Preprocessor1_Model01\n\n\n\n\nShow the code\nlr_best &lt;- lr_res %&gt;% \n  collect_metrics() %&gt;% \n  arrange(penalty) %&gt;% \n  slice(1)\n\nlr_auc &lt;- lr_res |&gt;\n    collect_predictions(parameters = lr_best) |&gt;\n    roc_curve(state_binary, .pred_0) |&gt;\n    mutate(model = \"Logistic Regression\")\n\n\nLe niveau de performance généré par ce modèle de régression logistique est correct mais pas optimal. La nature linéaire de l’équation de prédiction peut être trop restrictive pour cet ensemble de données. Lors de la prochaine étape, nous pourrions envisager d’utiliser un modèle non linéaire plus complexe, tel qu’une méthode d’ensemble basée sur les arbres."
  },
  {
    "objectID": "R_Analysis.html#tree-based-ensemble",
    "href": "R_Analysis.html#tree-based-ensemble",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "tree-based ensemble",
    "text": "tree-based ensemble\nComparons notre premier modèle à un random forest.\n\n\nShow the code\ncores &lt;- parallel::detectCores()\n\n\nrf_mod &lt;- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %&gt;% \n  set_engine(\"ranger\", num.threads = cores/2) %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nShow the code\nrf_recipe &lt;- \n  recipe(state_binary ~ ., data = df_other)\n\nrf_workflow &lt;- \n  workflow() %&gt;% \n  add_model(rf_mod) %&gt;% \n  add_recipe(rf_recipe)\n\nset.seed(345)\nrf_res &lt;- \n  rf_workflow %&gt;% \n  tune_grid(val_set,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(roc_auc))\n\n\n\n\nShow the code\nrf_best &lt;- \n  rf_res %&gt;% \n  select_best(metric = \"roc_auc\")\nrf_best\n\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1    38 Preprocessor1_Model07"
  },
  {
    "objectID": "R_Analysis.html#compare-both-models-using-roc-curves",
    "href": "R_Analysis.html#compare-both-models-using-roc-curves",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "Compare both models using ROC curves",
    "text": "Compare both models using ROC curves\n\n\nShow the code\nrf_auc &lt;- \n  rf_res %&gt;% \n  collect_predictions(parameters = rf_best) %&gt;% \n  roc_curve(state_binary, .pred_0) %&gt;% \n  mutate(model = \"Random Forest\")\n\nbind_rows(rf_auc, lr_auc) %&gt;% \n  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + \n  geom_path(lwd = 1.5, alpha = 0.8) +\n  geom_abline(lty = 3) + \n  coord_equal() + \n  scale_color_viridis_d(option = \"plasma\", end = .6)\n\n\n\n\n\n\n\n\n\nLa forêt aléatoire est systématiquement meilleure pour tous les seuils de probabilité des événements."
  },
  {
    "objectID": "R_Analysis.html#fit-the-final-model",
    "href": "R_Analysis.html#fit-the-final-model",
    "title": "Kickstarter Dataset Analysis in R",
    "section": "Fit the Final Model",
    "text": "Fit the Final Model\n\n\nShow the code\n# the last model\nlast_rf_mod &lt;- \n  rand_forest(mtry = 1, min_n = 38, trees = 1000) %&gt;% \n  set_engine(\"ranger\", num.threads = cores / 2, importance = \"impurity\") %&gt;% \n  set_mode(\"classification\")\n\n# the last workflow\nlast_rf_workflow &lt;- \n  rf_workflow %&gt;% \n  update_model(last_rf_mod)\n\n# the last fit\nset.seed(345)\nlast_rf_fit &lt;- \n  last_rf_workflow %&gt;% \n  last_fit(splits)\n\nlast_rf_fit %&gt;% \n  collect_metrics()\n\n\n# A tibble: 3 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.665 Preprocessor1_Model1\n2 roc_auc     binary         0.698 Preprocessor1_Model1\n3 brier_class binary         0.209 Preprocessor1_Model1\n\n\n\n\nShow the code\nlast_rf_fit %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip(num_features = 10)\n\n\n\n\n\n\n\n\n\nNous obtenons donc un modèle avec une précision de 66,5 % et un ROC AUC de 0,697. Bien que ces résultats ne soient pas extraordinaires, ils sont tout de même encourageants pour poursuivre l’exploration et améliorer l’efficacité de notre modèle."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kickstarter Dataset - A Data Science Analysis",
    "section": "",
    "text": "Executive Summary\nDans le cadre de cette analyse technique en science des données, j’ai choisi d’utiliser et découvrir le nouvel IDE de Posit (anciennement Rstudio). Ce nouvel IDE offre une intégration fluide entre différents langages de programmation, notamment R et Python mais également Julia ou SQL. En tant qu’utilisateur principal de R, cette approche m’a permis de réaliser l’analyse de manièere rapide en utilisant R tout en fournissant une version de Python au sein du même projet.\nJ’ai voulu faire l’analyse du jeu de donnée Kickstarter de manière simple et rapide. La réalisation de l’analyse en R a pris environ 2h30. Dans l’analyse en Python, curieux de voir si je pouvais améliorer mon premier modèle réalisé en R, j’ai décidé de tester directement un modèle lightGBM et sélectionné des variables un peu différentes - la traduction basique du code R en Python ne me semblant pas très intéressante.\n\n\nR Analysis - EDA & Data Modeling\n\nR Analysis - EDA & Data Modeling\n\n\n\nPython - lightGBM Model\n\nPython - lightGBM Model\n\n\n\nConclusion\nEn nous limitant à des modèles simples incluant très peu de variables, nous obtenons des résultats encourageants. Nous pouvons réfléchir à ajouter de nouvelles variables pour augmenter l’efficacité de nos modèles.\nLa prochaine étape est de déployer notre modèle, soit dans une API, soit dans une application web, permettant au client de tester la probabilité de réussite de son projet.\nComme tout modèle, le nôtre va voir sa performance fluctuer avec le temps. Il est donc important de réentraîner notre modèle constamment et de faire un suivi de celui-ci (MLOps). Il serait également préférable de faire tourner plusieurs modèles afin de pouvoir surveiller les différentes métriques. Le modèle le plus performant sera celui accessible via l’API et/ou l’application web.\nNous pourrions facilement intégrer un modèle d’IA générative pour proposer des suggestions de noms de projets afin d’augmenter le taux de probabilité de réussite de celui-ci.\n\n\nSet-up\nVoici l’installation réalisé pour reproduire dans les même conditions\n\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\nInstall R version 4.4.1 - Install R 4.4.1\nInstall Python 3.12.16 - Install Python 3.12.16\nInstall the latest Visual C++ Redistributable - Windows Visual C++ Redistributable Version\nInstall Positron IDE - Positron"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "I’m Thibault Senegas, a self-taught programmer and expert in R and Shiny. As a Lead Data Scientist and Chief Product Owner at quantum simulations*, I lead the creation of digital twins for companies, sports teams, and geographical regions. My focus is on merging cutting-edge data science with real-world applications.\nI hold an M.Sc. in International Business from HEC Montréal and a Master’s degree in Engineering from INP/ENSIACET in Toulouse, France. Before joining quantum simulations*, I honed my skills as a Data Scientist at IBM in their Advanced Analytics practice.\nI currently reside in Montréal, QC, with my wife and two sons.\nMy Resume"
  },
  {
    "objectID": "Python_model.html",
    "href": "Python_model.html",
    "title": "Kickstarter Dataset - An lightGBM Model",
    "section": "",
    "text": "Code\nimport chardet\nimport pandas as pd\n\nwith open('data/ks_dataset.csv', 'rb') as f:\n    result = chardet.detect(f.read(10000))  # Detect based on the first 10,000 bytes\nprint(result['encoding'])\n\ndf = pd.read_csv('data/ks_dataset.csv',\n                parse_dates=['deadline ', 'launched '],\n                encoding=result['encoding'])\n\ndf.columns = df.columns.str.strip()\ndf.head(5)\n\n\nWindows-1252\n\n\nC:\\Users\\seneg\\AppData\\Local\\Temp\\ipykernel_26864\\3643053608.py:8: DtypeWarning: Columns (13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv('data/ks_dataset.csv',\n\n\n\n\n\n\n\n\n\nID\nname\ncategory\nmain_category\ncurrency\ndeadline\ngoal\nlaunched\npledged\nstate\nbackers\ncountry\nusd pledged\nUnnamed: 13\nUnnamed: 14\nUnnamed: 15\nUnnamed: 16\n\n\n\n\n0\n1000002330\nThe Songs of Adelaide & Abullah\nPoetry\nPublishing\nGBP\n2015-10-09 11:36:00\n1000\n2015-08-11 12:12:28\n0\nfailed\n0\nGB\n0\nNaN\nNaN\nNaN\nNaN\n\n\n1\n1000004038\nWhere is Hank?\nNarrative Film\nFilm & Video\nUSD\n2013-02-26 00:20:50\n45000\n2013-01-12 00:20:50\n220\nfailed\n3\nUS\n220\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1000007540\nToshiCapital Rekordz Needs Help to Complete Album\nMusic\nMusic\nUSD\n2012-04-16 04:24:11\n5000\n2012-03-17 03:24:11\n1\nfailed\n1\nUS\n1\nNaN\nNaN\nNaN\nNaN\n\n\n3\n1000011046\nCommunity Film Project: The Art of Neighborhoo...\nFilm & Video\nFilm & Video\nUSD\n2015-08-29 01:00:00\n19500\n2015-07-04 08:35:03\n1283\ncanceled\n14\nUS\n1283\nNaN\nNaN\nNaN\nNaN\n\n\n4\n1000014025\nMonarch Espresso Bar\nRestaurants\nFood\nUSD\n2016-04-01 13:38:27\n50000\n2016-02-26 13:38:27\n52375\nsuccessful\n224\nUS\n52375\nNaN\nNaN\nNaN\nNaN"
  },
  {
    "objectID": "Python_model.html#prepare-the-target-column",
    "href": "Python_model.html#prepare-the-target-column",
    "title": "Kickstarter Dataset - An lightGBM Model",
    "section": "Prepare the target column",
    "text": "Prepare the target column\n\n\nCode\n# Filter rows where 'state' is in the specified list\ndf = df[df['state'].isin([\"failed\", \"canceled\", \"successful\", \"suspended\"])]\n\n# Add outcome column, \"successful\" == 1, others are 0\ndf = df.assign(state_binary=(df['state'] == 'successful').astype(int))"
  },
  {
    "objectID": "Python_model.html#prepare-features",
    "href": "Python_model.html#prepare-features",
    "title": "Kickstarter Dataset - An lightGBM Model",
    "section": "Prepare Features",
    "text": "Prepare Features\nExplorons de nouvelles variables ici, à commencer par le mois et le jour. Nous n’allons pas utiliser le sentiment du nom du projet ici.\n\n\nCode\ndf = df.assign(day=df.launched.dt.day,\n               month=df.launched.dt.month)\n\n\n\n\nCode\nfrom sklearn.preprocessing import LabelEncoder\n\ncat_features = ['main_category']\nencoder = LabelEncoder()\n\n# Apply the label encoder to each column\nencoded = df[cat_features].apply(encoder.fit_transform)\n\n\ndf_model = df[['goal', 'day', 'month', 'duration', 'state_binary']].join(encoded)\ndf_model['goal'] = pd.to_numeric(df_model['goal'])\ndf_model.head()\n\n\n\n\n\n\n\n\n\ngoal\nday\nmonth\nduration\nstate_binary\nmain_category\n\n\n\n\n1\n45000.0\n12\n1\n45\n0\n6\n\n\n2\n5000.0\n17\n3\n30\n0\n10\n\n\n3\n19500.0\n4\n7\n55\n0\n6\n\n\n4\n50000.0\n26\n2\n35\n1\n7\n\n\n5\n1000.0\n1\n12\n20\n1\n7"
  },
  {
    "objectID": "Python_model.html#training-validation-test-splits",
    "href": "Python_model.html#training-validation-test-splits",
    "title": "Kickstarter Dataset - An lightGBM Model",
    "section": "training, validation & test splits",
    "text": "training, validation & test splits\n\n\nCode\nvalid_fraction = 0.1\nvalid_size = int(len(df_model) * valid_fraction)\n\ntrain = df_model[:-2 * valid_size]\nvalid = df_model[-2 * valid_size:-valid_size]\ntest = df_model[-valid_size:]"
  },
  {
    "objectID": "Python_model.html#lighgbm",
    "href": "Python_model.html#lighgbm",
    "title": "Kickstarter Dataset - An lightGBM Model",
    "section": "lighGBM",
    "text": "lighGBM\n\n\nCode\nimport lightgbm as lgb\n\nfeature_cols = train.columns.drop('state_binary')\n\ndtrain = lgb.Dataset(train[feature_cols], label=train['state_binary'])\ndvalid = lgb.Dataset(valid[feature_cols], label=valid['state_binary'])\n\nparam = {'num_leaves': 64, 'objective': 'binary'}\nparam['metric'] = 'auc'\nnum_round = 1000\nbst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid])\n\n\n[LightGBM] [Info] Number of positive: 76306, number of negative: 126514\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001513 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 404\n[LightGBM] [Info] Number of data points in the train set: 202820, number of used features: 5\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376225 -&gt; initscore=-0.505601\n[LightGBM] [Info] Start training from score -0.505601\n\n\n\n\nCode\nfrom sklearn import metrics\nypred = bst.predict(test[feature_cols])\nscore = metrics.roc_auc_score(test['state_binary'], ypred)\n\nprint(f\"Test AUC score: {score}\")\n\nypred_binary = (ypred &gt; 0.5).astype(int)\naccuracy = metrics.accuracy_score(test['state_binary'], ypred_binary)\nprint(f\"Accuracy: {accuracy}\")\n\n\nTest AUC score: 0.6983113155286793\nAccuracy: 0.6705979804354686\n\n\nNous obtenons avec ce modèle un AUC de 0.698 et une accuracy de 67%. Des performances légérement meilleurs de notre modèle randomForest."
  }
]